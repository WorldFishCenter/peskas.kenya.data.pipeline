% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/preprocessing.R
\name{preprocess_kefs_surveys_v1}
\alias{preprocess_kefs_surveys_v1}
\title{Preprocess KEFS Survey Data}
\usage{
preprocess_kefs_surveys_v1(log_threshold = logger::DEBUG)
}
\arguments{
\item{log_threshold}{Logging threshold level (default: logger::DEBUG)}
}
\value{
No return value. Function processes the data and uploads the result as a Parquet file to Google Cloud Storage.
}
\description{
This function preprocesses raw KEFS (Kenya Fisheries Service) survey data from Google Cloud Storage.
It performs data cleaning, transformation, standardization of field names, type conversions,
and mapping to standardized taxonomic and gear names using Airtable reference tables.
}
\details{
The function performs the following main operations:
\enumerate{
\item \strong{Fetches metadata assets}: Retrieves taxonomic, gear, vessel, and landing site mappings from Airtable
based on the KEFS Kobo form asset ID
\item \strong{Downloads raw data}: Retrieves raw survey data from Google Cloud Storage
\item \strong{Extracts trip information}: Selects and renames relevant trip-level fields including:
\itemize{
\item Landing details (date, site, district, BMU)
\item Fishing ground and JCMA (Joint Community Management Area) information
\item Vessel details (type, name, registration, motorization, horsepower)
\item Trip details (crew size, start/end times, gear, mesh size, fuel)
\item Catch outcome indicators
}
\item \strong{Reshapes catch data}: Transforms catch details from wide to long format using \code{reshape_catch_data()}
\item \strong{Type conversions and calculations}:
\itemize{
\item Converts date/time fields to proper datetime format
\item Calculates trip duration in hours from start and end times
\item Converts numeric fields (hp, fishers, mesh size, fuel) to appropriate types
}
\item \strong{Joins trip and catch data}: Combines trip information with catch records using full join on submission_id
\item \strong{Standardizes names}: Maps survey labels to standardized names using \code{map_surveys()}:
\itemize{
\item Taxonomic names to scientific names and alpha3 codes
\item Gear types to standardized gear names
\item Vessel types to standardized vessel categories
\item Landing site codes to full site names
}
\item \strong{Uploads processed data}: Saves preprocessed data as a Parquet file to Google Cloud Storage
}
}
\section{Data Structure}{

The preprocessed output includes the following key fields:
\itemize{
\item \strong{Trip identifiers}: submission_id
\item \strong{Temporal}: landing_date, fishing_trip_start, fishing_trip_end, trip_duration
\item \strong{Spatial}: district, BMU, landing_site, fishing_ground, jcma, jcma_site
\item \strong{Vessel}: vessel_type, boat_name, vessel_reg_number, motorized, hp
\item \strong{Crew}: captain_name, no_of_fishers
\item \strong{Gear}: gear, mesh_size
\item \strong{Catch}: scientific_name, alpha3_code, total_catch_weight, price_per_kg, total_value
\item \strong{Operations}: fuel, catch_outcome, catch_shark
}
}

\section{Pipeline Integration}{

This function is part of the KEFS data pipeline sequence:
\enumerate{
\item \code{ingest_kefs_surveys_v1()} - Downloads raw data from Kobo
\item \strong{\code{preprocess_kefs_surveys_v1()}} - Cleans and standardizes data (this function)
\item Validation step (to be implemented)
\item Export step (to be implemented)
}
}

\examples{
\dontrun{
# Preprocess KEFS survey data
preprocess_kefs_surveys_v1()

# Run with custom logging level
preprocess_kefs_surveys_v1(log_threshold = logger::INFO)
}
}
\keyword{preprocessing}
\keyword{workflow}

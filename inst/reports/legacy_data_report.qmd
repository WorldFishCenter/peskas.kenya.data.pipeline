---
title: "WCS SSF legacy data"
format:
   html:
     self-contained: true
     theme:
       light: flatly
       dark: darkly
code-fold: true
code-summary: "Show the code"
editor: visual
css: style.css
toc: true
toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim

This document aims to outline the data structure and summarize the available information from small-scale fishery WCS surveys conducted between September 1995 and October 2022. The code and functions used in this analysis are part of an R package within a GitHub repository.

# Data Structure

The dataset includes small-scale fishery survey data collected from September 1995 to October 2022 across various landing sites or Beach Management Units (BMUs). Before conducting any analysis or visualization, the data were preprocessed and validated to:

-   Convert the data into a tidy format. A dataset is considered tidy when each column represents a single variable, each row corresponds to one observation, and all variables have the same unit of observation. (For more information, visit this [link](https://dimewiki.worldbank.org/Tidying_Data)).

-   Retain informative and meaningful variables while discarding any biased, stale, or non-informative variables. Additionally, variables derived from the core data were removed, as they can be generated as needed, making the dataset lighter and more efficient.

-   Ensure that categorical values are consistent across the dataset.

The details of the data preprocessing and validation will be covered in the next section. For now, the dataset contains the following variables:

```{r, warning=FALSE, message=FALSE, fig.width=7, fig.height=7}
library(magrittr)
library(ggplot2)


setwd("../..")
getwd()
conf <- peskas.kenya.data.pipeline::read_config()

legacy_data <-
  peskas.kenya.data.pipeline::mdb_collection_pull(
    collection_name = "legacy-validated",
    db_name = "pipeline",
    connection_string = conf$storage$mongodb$connection_string
  ) %>%
  dplyr::as_tibble()

data_table <- dplyr::tibble(
  N. = seq(1, length(legacy_data)),
  Variable = names(legacy_data),
  Type = c(
    "Categorical", "Categorical", "Categorical", "Date", "Numeric", "Numeric", "Categorical",
    "Categorical", "Categorical", "Text", "Categorical", "Numeric", "Numeric"
  ),
  Description = c(
    "Unique identifier for each survey",
    "Unique identifier for each catch in the survey",
    "Name of the site where landing occurs (BMU)",
    "Date of fishing landing",
    "Number of fishers involved in the catch",
    "Number of boats used",
    "Specific type of fishing gear used",
    "Broad type of fishing gear used",
    "Broad category of fish caught",
    "Specific category of the fish caught",
    "Ecological category of the fish",
    "Price per unit of catch",
    "Weight of the catch in kilograms"
  )
)

reactable::reactable(data_table,
  striped = TRUE,
  highlight = TRUE,
  pagination = FALSE,
  columns = list(
    "N." = reactable::colDef(maxWidth = 100),
    Description = reactable::colDef(minWidth = 240) # overrides the default
  ),
  theme = reactable::reactableTheme(
    borderColor = "#dfe2e5",
    stripedColor = "#f6f8fa",
    highlightColor = "#f0f5f9",
    cellPadding = "8px 12px",
    style = list(
      fontFamily = "-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, Arial, sans-serif"
    )
  )
)
```

Below is a breakdown of the categorical variables:

```{r, warning=FALSE, message=FALSE}
ranked <-
  legacy_data %>%
  dplyr::select(dplyr::where(is.character)) %>%
  dplyr::select(-c("landing_date", "survey_id", "catch_id")) %>%
  tidyr::pivot_longer(dplyr::everything(), names_to = "variable", values_to = "value") %>%
  dplyr::count(variable, value)

catch_names_minor <-
  ranked %>%
  dplyr::filter(variable == "catch_name") %>%
  dplyr::mutate(
    tot = sum(n),
    perc = n / tot * 100
  ) %>%
  dplyr::filter(perc < 0.5) %>%
  dplyr::pull(value)

ranked %>%
  dplyr::mutate(value = dplyr::case_when(
    variable == "catch_name" & value %in% catch_names_minor ~ "Other",
    TRUE ~ value
  )) %>%
  ggplot(aes(x = tidytext::reorder_within(value, n, variable), y = n)) +
  geom_bar(aes(fill = variable), stat = "identity", alpha = 0.5) +
  facet_wrap(~variable, scales = "free") +
  tidytext::scale_x_reordered() +
  coord_flip() +
  theme_minimal() +
  ggsci::scale_fill_jama() +
  theme(
    panel.grid = element_blank(),
    legend.position = ""
  ) +
  labs(
    title = "Ranking of categorical variables",
    x = "",
    y = ""
  )
```

# Data elaboration

## Preprocessing

Preprocessing operations were performed using the functions `prepare_legacy_landings` and `preprocess_legacy_landings`. These first function accomplishes the following tasks:

-   Variables were renamed according to the [Snake case convention](https://developer.mozilla.org/en-US/docs/Glossary/Snake_case).

-   A unique ID was generated for each survey and catch.

-   Variables derived from the core data were dropped, as they can be generated when needed. These include derived variables from the landing date such as "Month", "Year", "Day", and "Month". Additionally, static information related to landing sites was removed and stored in static metadata tables on Google Sheets, where it can be accessed as needed along the pipeline. This includes management features and size areas associated with the BMUs.

-   In some cases, the names of the same species were misspelled. For example, surgeonfish were named "surgeoms", "surgeon", or "surgeonfish", and zebrafish were named "zebra" or "zebrafish". The function `clean_catch_names` assigned a unique name to each fish group.

## Validation

Currently, validation operations were performed to assess the validity of the landing date, the number of boats, the number of fishermen, and the catch weight. The process involves the examination of outliers and anomalous values, which, when identified, are excluded from further analysis by replacing their values with `NA`. The validation procedure is organized through a systematic labeling process, wherein each data entry is assigned a specific code reflecting its validation status.

The landing date was validated by ensuring that dates were not earlier than 1990. For the other variables, validation was performed using the Median Absolute Deviation (MAD) to identify potential outliers. Specifically, MAD was used to detect outliers based on the data's distribution itself, rather than applying an arbitrary threshold. By adjusting the value of `k`, we control the sensitivity to outliersâ€”lower values of `k` make the method more sensitive, flagging more points as outliers, while higher values make it less sensitive. This approach ensures that outliers are identified in relation to the natural variability of the data, providing a robust method for detecting anomalies without imposing an external standard.

In the histogram below, the dashed line indicates the outlier threshold at 8.34 boats, determined by the data using a `k` value of 1.5. Adjusting `k` changes sensitivity: lower `k` detects more outliers, while higher `k` detects fewer.

```{r, warning=FALSE, message=FALSE}
thr <-
  univOutl::LocScaleB(legacy_data$n_boats, logt = TRUE, k = 1.5) %>%
  magrittr::extract2("bounds")
upb <- (exp(thr) - 1)[2]


legacy_data %>%
  ggplot(aes(n_boats)) +
  theme_minimal() +
  geom_histogram(bins = 30, fill = "#52817f", color = "white", alpha = 0.5) +
  geom_vline(xintercept = upb, color = "firebrick", linetype = 2) +
  theme(panel.grid = element_blank()) +
  annotate("text", x = upb + 0.5, y = Inf, label = "k value = 1.5\n(8.34 boats)", color = "firebrick", vjust = 2, hjust = 0) +
  scale_y_continuous(labels = scales::comma) +
  scale_x_continuous(n.breaks = 10) +
  coord_cartesian(expand = FALSE) +
  labs(
    x = "Number of boats",
    y = "Count",
    title = "Outlier detection for number of boats using MAD"
  )
```

The same criteria were applied to the number of fishermen and catch weight. For the latter, data were grouped based on the gear type, as fishing methods can significantly influence catch sizes. By grouping catch weight data by gear type, we account for these variations, allowing for a more accurate identification of outliers specific to each gear category.

A `k` value of 3 was used for each feature.

# Data Analysis

## Temporal distribution

```{r, warning=FALSE, message=FALSE, fig.width=7, fig.height=7}
quarter_format <- function(date) {
  year <- lubridate::year(date)
  quarter <- lubridate::quarter(date)
  return(paste0("Q", quarter, "\n", year))
}


basedata <-
  legacy_data %>%
  dplyr::mutate(landing_date = as.Date(as.POSIXct(landing_date, origin = "1970-01-01"))) %>%
  dplyr::group_by(survey_id) %>%
  dplyr::summarise(dplyr::across(dplyr::everything(), ~ dplyr::first(.x))) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(quarter_date = lubridate::floor_date(landing_date, unit = "quarter")) %>%
  dplyr::group_by(quarter_date, landing_site) %>%
  dplyr::count() %>%
  dplyr::ungroup() %>%
  tidyr::complete(quarter_date, landing_site, fill = list(n = 0))

main_plot <-
  basedata %>%
  ggplot() +
  theme_bw() +
  geom_tile(aes(x = quarter_date, y = reorder(landing_site, n), fill = n, alpha = log(n)), color = "white", size = 0.3) +
  # facet_grid(sector ~ ., scales = "free", , space = "free") +
  scale_fill_viridis_c(direction = -1) +
  coord_cartesian(expand = FALSE) +
  theme(
    panel.grid = element_blank(),
    strip.background = element_rect(fill = "white"),
    legend.position = "bottom",
    legend.key.width = unit(1, "cm"),
    strip.text.y = element_text(angle = 0, vjust = 0.5, hjust = 0.5, face = "bold"),
  ) +
  guides(alpha = "none") +
  scale_x_date(
    date_breaks = "3 years",
    labels = quarter_format,
    expand = c(0, 0)
  ) +
  labs(
    title = "BMUs activity",
    subtitle = "Ranked temporal distribution of survey activities across BMU's from\nSep 1995 to Oct 2022, illustrating survey frequency over time.",
    x = "Quarter of the Year",
    fill = "Number of surveys",
    y = ""
  )

side_plot <-
  basedata %>%
  dplyr::group_by(landing_site) %>%
  dplyr::summarise(total_surveys = sum(n, na.rm = T)) %>%
  ggplot() +
  theme_minimal() +
  geom_bar(aes(y = reorder(landing_site, total_surveys), x = total_surveys), stat = "identity", fill = "#52817f", alpha = 0.5) +
  geom_text(aes(y = reorder(landing_site, total_surveys), x = total_surveys, label = scales::label_number(scale = 1 / 1000, suffix = "K")(total_surveys)),
    hjust = -0.1, size = 3
  ) +
  labs(x = "", y = "") +
  theme(
    panel.grid = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  coord_cartesian(x = c(0, 11000))

cowplot::plot_grid(main_plot,
  side_plot + theme(plot.margin = margin(0, 10, 0, -5)),
  ncol = 2,
  rel_widths = c(4, 1),
  align = "h"
)
```